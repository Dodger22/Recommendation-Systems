{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b5d31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]\n",
      "Spark version: 3.1.2\n"
     ]
    }
   ],
   "source": [
    "# set the environment path to find Recommenders\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "#os.environ[\"PYSPARK_PYTHON\"]=r\"C:\\Users\\mirza\\AppData\\Local\\Programs\\Python\\Python39\"\n",
    "import pickle\n",
    "import sys\n",
    "import pyspark\n",
    "from pyspark.ml.recommendation import ALS\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import StringType, FloatType, IntegerType, LongType\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from recommenders.utils.timer import Timer\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.utils.notebook_utils import is_jupyter\n",
    "from recommenders.datasets.spark_splitters import spark_random_split\n",
    "from recommenders.evaluation.spark_evaluation import SparkRatingEvaluation, SparkRankingEvaluation\n",
    "from recommenders.utils.spark_utils import start_or_get_spark\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Spark version: {}\".format(pyspark.__version__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84e1ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K = 5\n",
    "COL_USER = \"userId\"\n",
    "COL_ITEM = \"itemId\"\n",
    "COL_RATING = \"rating\"\n",
    "COL_TIMESTAMP = \"timestamp\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec7f348e",
   "metadata": {},
   "source": [
    "movies = pd.read_csv(r'C:\\Users\\mirza\\Desktop\\dataset\\MovieLens-Credits\\movies_metadata.csv', \n",
    "        encoding = \"ISO-8859-1\"\n",
    "    )\n",
    "\n",
    "movies = movies[movies[\"id\"].apply(lambda x: x.isnumeric())]\n",
    "movies[\"id\"]= movies[\"id\"].astype(int)\n",
    "movies.rename(columns = {'id':\"itemId\"}, inplace = True)\n",
    "\n",
    "import ast\n",
    "\n",
    "def convert(obj):\n",
    "    L = []\n",
    "    for i in ast.literal_eval(obj):\n",
    "        L.append(i[\"name\"])\n",
    "    \n",
    "    return L\n",
    "movies[\"genres\"]= movies[\"genres\"].apply(convert)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3762f5cb",
   "metadata": {},
   "source": [
    "ratings_data= pd.read_csv(\n",
    "        r'C:\\Users\\mirza\\Desktop\\dataset\\MovieLens-Credits\\ratings.csv', nrows=2500000,\n",
    "        encoding = \"ISO-8859-1\",\n",
    "        header = 0,\n",
    "        names=[\"userId\", \"itemId\", \"rating\", 'timestamp']\n",
    "    )\n",
    "ratings_data = pd.merge(ratings_data[[\"userId\",\"itemId\",\"rating\"]], movies[[\"itemId\",\"genres\", \"title\"]], how=\"inner\", on=\"itemId\")\n",
    "\n",
    "ratings = ratings_data[[\"userId\",\"itemId\", \"rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ba1acde",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pickle.load(open(\"svd_ratings_data.pkl\",\"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b362bd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>itemId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>110</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>110</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>110</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>110</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  itemId  rating\n",
       "0       1     110     1.0\n",
       "1      11     110     3.5\n",
       "2      22     110     5.0\n",
       "3      24     110     5.0\n",
       "4      29     110     3.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c625b1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = start_or_get_spark(\"ALS PySpark\", memory=\"16g\")\n",
    "spark.conf.set(\"spark.sql.analyzer.failAmbiguousSelfJoin\", \"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b17a8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_data=spark.createDataFrame(ratings) \n",
    "#movie=spark.createDataFrame(movies) \n",
    "\n",
    "ratings_data =ratings_data.withColumn(\"userId\", col(\"userId\").cast(\"integer\"))\n",
    "ratings_data =ratings_data.withColumn(\"itemId\", col(\"itemId\").cast(\"integer\"))\n",
    "ratings_data =ratings_data.withColumn(\"rating\", col(\"rating\").cast(\"double\"))\n",
    "#ratings_data =ratings_data.withColumn(\"timestamp\", col(\"timestamp\").cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8258209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+\n",
      "|userId|itemId|rating|\n",
      "+------+------+------+\n",
      "|     1|   110|   1.0|\n",
      "|    11|   110|   3.5|\n",
      "|    22|   110|   5.0|\n",
      "|    24|   110|   5.0|\n",
      "|    29|   110|   3.0|\n",
      "|    30|   110|   5.0|\n",
      "|    33|   110|   3.0|\n",
      "|    34|   110|   5.0|\n",
      "|    49|   110|   4.0|\n",
      "|    56|   110|   4.0|\n",
      "+------+------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b72271b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1099679, 3)\n"
     ]
    }
   ],
   "source": [
    "print((ratings_data.count(), len(ratings_data.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca8af894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId , IntegerType\n",
      "itemId , IntegerType\n",
      "rating , DoubleType\n"
     ]
    }
   ],
   "source": [
    "for field in ratings_data.schema.fields:\n",
    "    print(field.name +\" , \"+str(field.dataType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87b91aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N train 935070\n",
      "N test 164609\n"
     ]
    }
   ],
   "source": [
    "train, test = spark_random_split(ratings_data, ratio=0.85, seed=123)\n",
    "print (\"N train\", train.cache().count())\n",
    "print (\"N test\", test.cache().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e6bbb9",
   "metadata": {},
   "source": [
    "## Find best model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d18a78fa",
   "metadata": {},
   "source": [
    "header = {\n",
    "    \"userCol\": \"userId\",\n",
    "    \"itemCol\": \"itemId\",\n",
    "    \"ratingCol\": \"rating\",\n",
    "}\n",
    "\n",
    "def tune_ALS(train_data, validation_data, maxIter, regParams, ranks):\n",
    "    # initial\n",
    "    min_error = float('inf')\n",
    "    best_rank = -1\n",
    "    best_regularization = 0\n",
    "    best_model = None\n",
    "    for rank in ranks:\n",
    "        for reg in regParams:\n",
    "            # get ALS model\n",
    "            aLs = ALS(**header).setMaxIter(maxIter).setRank(rank).setRegParam(reg)\n",
    "            # train ALS model\n",
    "            model = aLs.fit(train_data)\n",
    "            # evaluate the model by computing the RMSE on the validation data\n",
    "            predictions = model.transform(validation_data)\n",
    "            evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                               predictionCol=\"prediction\")\n",
    "            rmse = evaluator.evaluate(predictions)\n",
    "            print('{} latent factors and regularization = {}: '\n",
    "                  'validation RMSE is {}'.format(rank, reg, rmse))\n",
    "            if rmse < min_error:\n",
    "                min_error = rmse\n",
    "                best_rank = rank\n",
    "                best_regularization = reg\n",
    "                best_model = model\n",
    "    print('\\nThe best model has {} latent factors and '\n",
    "          'regularization = {}'.format(best_rank, best_regularization))\n",
    "    return best_model\n",
    "\n",
    "\n",
    "maxIterc=20\n",
    "regParams=[0.001, 0.01, 0.05]\n",
    "ranks=[8, 10, 12, 14, 16, 18, 20]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6675ddef",
   "metadata": {},
   "source": [
    "tune_ALS(train, test, maxIterc, regParams, ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29ea150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "header = {\n",
    "    \"userCol\": COL_USER,\n",
    "    \"itemCol\": COL_ITEM,\n",
    "    \"ratingCol\": COL_RATING,\n",
    "}\n",
    "\n",
    "\n",
    "als = ALS(\n",
    "    rank=50,\n",
    "    maxIter=15,\n",
    "    implicitPrefs=False,\n",
    "    regParam=0.05,\n",
    "    coldStartStrategy='drop',\n",
    "    nonnegative=False,\n",
    "    seed=42,\n",
    "    **header\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5919e8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 12.154862599999994 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with Timer() as train_time:\n",
    "    model = als.fit(train)\n",
    "\n",
    "print(\"Took {} seconds for training.\".format(train_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0c7c680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 525.3789886 seconds for prediction.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as test_time:\n",
    "\n",
    "    users = train.select(COL_USER).distinct()\n",
    "    items = train.select(COL_ITEM).distinct()\n",
    "    user_item = users.crossJoin(items)\n",
    "    dfs_pred = model.transform(user_item)\n",
    "\n",
    "    dfs_pred_exclude_train = dfs_pred.alias(\"pred\").join(\n",
    "        train.alias(\"train\"),\n",
    "        (dfs_pred[COL_USER] == train[COL_USER]) & (dfs_pred[COL_ITEM] == train[COL_ITEM]),\n",
    "        how='outer'\n",
    "    )\n",
    "\n",
    "    top_all = dfs_pred_exclude_train.filter(dfs_pred_exclude_train[f\"train.{COL_RATING}\"].isNull()) \\\n",
    "        .select('pred.' + COL_USER, 'pred.' + COL_ITEM, 'pred.' + \"prediction\")\n",
    "\n",
    "    top_all.cache().count()\n",
    "\n",
    "print(\"Took {} seconds for prediction.\".format(test_time.interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95ada8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----------+\n",
      "|userId|itemId|prediction|\n",
      "+------+------+----------+\n",
      "|     1|   587| 2.7120118|\n",
      "|     1|   869| 2.7746842|\n",
      "|     1|  1677|  2.219958|\n",
      "|     1|  1702| 1.9299065|\n",
      "|     1|  1720|  1.237754|\n",
      "|     1|  1892| 3.3349123|\n",
      "|     1|  2086| 2.3612878|\n",
      "|     1|  2202| 2.9522777|\n",
      "|     1|  2324| 3.9532568|\n",
      "|     1|  2667| 2.4829562|\n",
      "+------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_all.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3028832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b92caa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_eval = SparkRankingEvaluation(test, prediction, k = TOP_K, col_user=COL_USER, col_item=COL_ITEM, \n",
    "                                    col_rating=COL_RATING, col_prediction=\"prediction\", \n",
    "                                    relevancy_method=\"top_k\")\n",
    "rmse_evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                               predictionCol=\"prediction\")\n",
    "mae_evaluator = RegressionEvaluator(metricName=\"mae\", labelCol=\"rating\",\n",
    "                               predictionCol=\"prediction\")\n",
    "\n",
    "mae = mae_evaluator.evaluate(prediction)\n",
    "rmse = rmse_evaluator.evaluate(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd65a5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\tALS\n",
      "Top K:\t5\n",
      "RMSE:\t0.861481\n",
      "MAE:\t0.663448\n",
      "MAP:\t0.792191\n",
      "NDCG:\t0.999950\n",
      "Precision@K:\t0.670452\n",
      "Recall@K:\t0.792187\n"
     ]
    }
   ],
   "source": [
    "print(\"Model:\\tALS\",\n",
    "      \"Top K:\\t%d\" % rank_eval.k,\n",
    "      \"RMSE:\\t%f\" % rmse,\n",
    "      \"MAE:\\t%f\" % mae,\n",
    "      \"MAP:\\t%f\" % rank_eval.map_at_k(),\n",
    "      \"NDCG:\\t%f\" % rank_eval.ndcg_at_k(),\n",
    "      \"Precision@K:\\t%f\" % rank_eval.precision_at_k(),\n",
    "      \"Recall@K:\\t%f\" % rank_eval.recall_at_k(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6dd2f071",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = prediction.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2578f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write().overwrite().save(r\"C:\\Users\\mirza\\wzrdtls\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37",
   "language": "python",
   "name": "python37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
